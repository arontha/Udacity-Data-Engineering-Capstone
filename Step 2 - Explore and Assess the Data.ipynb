{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore and Clean Data\n",
    "- Identify data quality issues, like missing values, duplicate data, etc.\n",
    "- Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Functions to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#function to describe dataframe from step 1\n",
    "def stats_on_df(df, name):\n",
    "    print(\"\\nThere are {} rows and {} columns of data in the {} file\".format(len(df), len(df.columns), name))\n",
    "    print(\"columns are {}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#function to compare series to identify similarity\n",
    "def matcher(series1, series2):\n",
    "    matches = [i for i in series1 if i in series2]\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Airports\n",
    "Let's start with the **airport** data set found in /data_first_cleaning/airports.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 55075 rows and 12 columns of data in the airports file\n",
      "columns are Index(['airport_identifier', 'airport_size', 'airport_name', 'elevation_ft',\n",
      "       'continent', 'country', 'iso_region', 'municipality', 'gps_code',\n",
      "       'iata_code', 'local_code', 'coordinates'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "airport_df = pd.read_csv(\"data_first_cleaning/airports.csv\")\n",
    "stats_on_df(airport_df,\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.airport_size.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will assume that only airports are relevant to immigration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 39142 rows of data in the airport file.\n"
     ]
    }
   ],
   "source": [
    "airports = ['small_airport', 'medium_airport', 'large_airport']\n",
    "airport_df = airport_df[airport_df.airport_size.isin(airports)]\n",
    "print(\"\\nThere are {} rows of data in the airport file.\".format(len(airport_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continents = [nan 'OC' 'AF' 'AN' 'AS' 'SA' 'EU']\n",
      "countries = ['US' 'PR' 'MH' 'SO' 'AQ' 'PG' 'SD' 'SA' 'AE' 'SS' 'CN' 'AF' 'SB' 'CO' 'AU'\n",
      " 'MG' 'TD' 'AL' 'AM' 'MX' 'MZ' 'PW' 'NR' 'AO' 'AR' 'AS' 'GA' 'AZ' 'BA' 'BB'\n",
      " 'BE' 'BF' 'BG' 'GL' 'BI' 'IS' 'BJ' 'OM' 'XK' 'KE' 'BO' 'BR' 'BS' 'CV' 'BW'\n",
      " 'BY' 'UA' 'LR' 'BZ' 'CA' 'GB' 'CD' 'CF' 'CG' 'PH' 'MR' 'CH' 'CL' 'CM' 'MA'\n",
      " 'CR' 'CU' 'CY' 'CZ' 'SK' 'PA' 'DZ' 'DE' 'ID' 'GH' 'RU' 'CI' 'DK' 'NG' 'NE'\n",
      " 'TN' 'TG' 'EC' 'EE' 'FI' 'EG' 'GG' 'JE' 'IM' 'FK' 'EH' 'NL' 'IE' 'FO' 'LU'\n",
      " 'NO' 'PL' 'ER' 'MN' 'ES' 'PT' 'SE' 'ET' 'LV' 'LT' 'ZA' 'SZ' 'GQ' 'SH' 'MU'\n",
      " 'FJ' 'IO' 'ZM' 'FM' 'KM' 'YT' 'RE' 'TF' 'ST' 'FR' 'SC' 'ZW' 'MW' 'LS' nan\n",
      " 'ML' 'GM' 'GE' 'GF' 'SL' 'GW' 'GN' 'SN' 'GR' 'GT' 'TZ' 'GY' 'SR' 'DJ' 'LY'\n",
      " 'HN' 'VN' 'HR' 'KZ' 'RW' 'HT' 'HU' 'UG' 'TL' 'IL' 'IN' 'IQ' 'IR' 'JP' 'IT'\n",
      " 'JM' 'JO' 'KG' 'KP' 'KR' 'MY' 'PM' 'SI' 'LK' 'MT' 'AT' 'RO' 'TR' 'MD' 'MK'\n",
      " 'GI' 'RS' 'ME' 'TC' 'DO' 'MM' 'NI' 'SV' 'KY' 'NC' 'CK' 'TO' 'KI' 'TV' 'NU'\n",
      " 'WF' 'NP' 'WS' 'PF' 'VU' 'NZ' 'BH' 'KW' 'LB' 'KH' 'PK' 'SY' 'QA' 'YE' 'LA'\n",
      " 'PE' 'MP' 'GU' 'UM' 'TH' 'PS' 'PY' 'TW' 'SG' 'SM' 'UY' 'VE' 'AG' 'DM' 'GP'\n",
      " 'MQ' 'MF' 'BL' 'GD' 'VI' 'TJ' 'KN' 'LC' 'TM' 'AW' 'BQ' 'CW' 'SX' 'AI' 'MS'\n",
      " 'TT' 'VG' 'VC' 'BM' 'UZ' 'BD' 'HK' 'MO' 'BT' 'MV' 'BN' 'CC' 'CX' 'NF']\n"
     ]
    }
   ],
   "source": [
    "print(\"continents = {}\".format(airport_df.continent.unique())) #has nan\n",
    "print(\"countries = {}\".format(airport_df.country.unique())) #no nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0% of the continent data is nan\n"
     ]
    }
   ],
   "source": [
    "nans_cont = len(airport_df[airport_df.continent.isna()])/len(airport_df)\n",
    "print(\"{}% of the continent data is nan\".format(round(nans_cont*100,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan_countries = airport_df.country[airport_df.continent.isna()].unique()\n",
    "notnan_countries = airport_df.country[airport_df.continent.notna()].unique()\n",
    "matcher(nan_countries, notnan_countries)\n",
    "#matches = [i for i in nan_countries if i in notnan_countries] #see if there is a country-based logic behind nans in continent data\n",
    "#print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since there is no intersection between these 2 arrays, we conclude that continent being nan is directly based on specific countries. Let's add the continent for the countries with nan. Data is cross-referenced with https://www.nationsonline.org/oneworld/country_code_list.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'PR', 'MX', 'BB', 'GL', 'BS', 'BZ', 'CA', 'CR', 'CU', 'PA',\n",
       "       'GT', 'HN', 'HT', 'JM', 'PM', 'TC', 'DO', 'NI', 'SV', 'KY', 'AG',\n",
       "       'DM', 'GP', 'MQ', 'MF', 'BL', 'GD', 'VI', 'KN', 'LC', 'AW', 'BQ',\n",
       "       'CW', 'SX', 'AI', 'MS', 'TT', 'VG', 'VC', 'BM'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#north america countries in nan_countries array according to https://www.nationsonline.org\n",
    "na_countries = ['US', 'PR', 'MX', 'BB', 'BS', 'BZ', 'CA', 'CR', 'CU', 'PA',\n",
    "       'GT', 'HN', 'HT', 'JM', 'PM', 'TC', 'DO', 'NI', 'SV', 'KY', 'AG',\n",
    "       'DM', 'GP', 'MQ', 'MF', 'BL', 'GD', 'VI', 'KN', 'LC', 'AW', 'AI', 'MS', 'TT', 'VG', 'VC', 'BM']\n",
    "    \n",
    "eu_countries = ['GL']\n",
    "\n",
    "other_countries = ['BQ','CW', 'SX'] #will be dropped since they are not in the given source of country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 39137 rows of data in the airport file.\n"
     ]
    }
   ],
   "source": [
    "airport_df.loc[airport_df['country'].isin(na_countries), 'continent'] = 'NA'\n",
    "airport_df.loc[airport_df['country'].isin(eu_countries), 'continent'] = 'EU'\n",
    "airport_df = airport_df[airport_df['continent'].notna()]\n",
    "print(\"\\nThere are {} rows of data in the airport file.\".format(len(airport_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have now cleaned the continent column and only lost 5 rows of data due to potentially obsolete information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29173 rows with airport_identifier=gps_code.\n",
      "12305 rows with gps_code=local_code.\n",
      "11725 rows with airport_identifier=local_code.\n"
     ]
    }
   ],
   "source": [
    "print(str(len(airport_df[airport_df.airport_identifier==airport_df.gps_code])) + \" rows with airport_identifier=gps_code.\")\n",
    "print(str(len(airport_df[airport_df.gps_code==airport_df.local_code])) + \" rows with gps_code=local_code.\")\n",
    "print(str(len(airport_df[airport_df.airport_identifier==airport_df.local_code])) + \" rows with airport_identifier=local_code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A lot of the data contains the same values for ident, gps_code, and local_code columns, but there is still a significant amount of data with different values in these columns therefore we will maintain all 3 columns columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df.elevation_ft = pd.to_numeric(airport_df.elevation_ft, downcast='integer') #condense data\n",
    "airport_df.head(2)\n",
    "airport_df = airport_df[pd.notnull(airport_df.iata_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df.to_csv('data_second_cleaning/airports.csv', index=False) #save for to use in step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Cities (Demographics)\n",
    "Next we'll work with with the **cities** data set found in /data_first_cleaning/cities.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 2891 rows and 12 columns of data in the cities file\n",
      "columns are Index(['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
      "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
      "       'Average Household Size', 'State Code', 'Race', 'Race Population'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"data_first_cleaning/cities.csv\")\n",
    "stats_on_df(cities_df,\"cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Race Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  \\\n",
       "0                    2.60         MD         Hispanic or Latino   \n",
       "1                    2.39         MA                      White   \n",
       "2                    2.58         AL                      Asian   \n",
       "3                    3.18         CA  Black or African-American   \n",
       "4                    2.73         NJ                      White   \n",
       "\n",
       "   Race Population  \n",
       "0            25924  \n",
       "1            58723  \n",
       "2             4759  \n",
       "3            24437  \n",
       "4            76402  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hispanic or Latino', 'White', 'Asian', 'Black or African-American',\n",
       "       'American Indian and Alaska Native'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.Race.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For our purposes, we do not want separate rows for each city. We will reshape our data first to have 1 row per city. Then, since our immigration data does not give us a destination city but rather a destination state. We will condense the data into 1 row per state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cities_melted = pd.melt(cities_df, id_vars=['Race'], value_vars=['Race Population'])\n",
    "#cities_grouped = cities_df.groupby(['Race']).aggregate('sum')\n",
    "cities_index = list(cities_df.columns)\n",
    "cities_index.remove('Race')\n",
    "cities_index.remove('Race Population')\n",
    "cities_pivot = pd.pivot_table(cities_df, values='Race Population', index=cities_index, columns=['Race'], aggfunc=np.sum)\n",
    "cities_pivot = cities_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>14449.0</td>\n",
       "      <td>33222.0</td>\n",
       "      <td>95487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>38.1</td>\n",
       "      <td>96886.0</td>\n",
       "      <td>100667.0</td>\n",
       "      <td>197553</td>\n",
       "      <td>12878.0</td>\n",
       "      <td>10024.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>OH</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>9033.0</td>\n",
       "      <td>66551.0</td>\n",
       "      <td>3684.0</td>\n",
       "      <td>129192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>FL</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>4176.0</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10336.0</td>\n",
       "      <td>6577.0</td>\n",
       "      <td>34897.0</td>\n",
       "      <td>63666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>CA</td>\n",
       "      <td>41.4</td>\n",
       "      <td>37747.0</td>\n",
       "      <td>40867.0</td>\n",
       "      <td>78614</td>\n",
       "      <td>4504.0</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>2.52</td>\n",
       "      <td>CA</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>27984.0</td>\n",
       "      <td>7364.0</td>\n",
       "      <td>8265.0</td>\n",
       "      <td>44232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>GA</td>\n",
       "      <td>445.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>53440.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>17160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race     City State  Median Age  Male Population  Female Population  \\\n",
       "0     Abilene    TX        31.3          65212.0            60664.0   \n",
       "1       Akron    OH        38.1          96886.0           100667.0   \n",
       "2     Alafaya    FL        33.5          39504.0            45760.0   \n",
       "3     Alameda    CA        41.4          37747.0            40867.0   \n",
       "4      Albany    GA        33.3          31695.0            39414.0   \n",
       "\n",
       "Race  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0               125876              9367.0        8129.0   \n",
       "1               197553             12878.0       10024.0   \n",
       "2                85264              4176.0       15842.0   \n",
       "3                78614              4504.0       18841.0   \n",
       "4                71109              5409.0         861.0   \n",
       "\n",
       "Race  Average Household Size State Code  American Indian and Alaska Native  \\\n",
       "0                       2.64         TX                             1813.0   \n",
       "1                       2.24         OH                             1845.0   \n",
       "2                       2.94         FL                                NaN   \n",
       "3                       2.52         CA                             1329.0   \n",
       "4                       2.38         GA                              445.0   \n",
       "\n",
       "Race    Asian  Black or African-American  Hispanic or Latino     White  \n",
       "0      2929.0                    14449.0             33222.0   95487.0  \n",
       "1      9033.0                    66551.0              3684.0  129192.0  \n",
       "2     10336.0                     6577.0             34897.0   63666.0  \n",
       "3     27984.0                     7364.0              8265.0   44232.0  \n",
       "4       650.0                    53440.0              1783.0   17160.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_pivot.State = cities_pivot['State Code']\n",
    "cities_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115649397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_pivot = cities_pivot.groupby(['State']).aggregate('sum')\n",
    "cities_pivot2 = cities_pivot.loc[:,['State', 'Median Age', 'Average Household Size']]\n",
    "states_pivot2 = cities_pivot2.groupby(['State']).aggregate('mean')\n",
    "states_pivot.loc[:,['Median Age', 'Average Household Size']] = round(states_pivot2.loc[:,['Median Age', 'Average Household Size']],2)\n",
    "sum(states_pivot['Total Population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Unfortunately, this data does not look to be complete as the US population is greater than 300 million. To address this, we will assume that the ratios are still valid and convert our data to percentages. We will convert total population to % of the entire country and the other population columns as % of the total for the specific state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>32.20</td>\n",
       "      <td>51.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>298695</td>\n",
       "      <td>9.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>36.23</td>\n",
       "      <td>47.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1049629</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>49.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>47.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>32.77</td>\n",
       "      <td>48.6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>589879</td>\n",
       "      <td>5.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>35.04</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>4499542</td>\n",
       "      <td>5.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>36.18</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>24822460</td>\n",
       "      <td>3.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>39.7</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race   Median Age  Male Population  Female Population  Total Population  \\\n",
       "State                                                                     \n",
       "AK          32.20             51.2               48.8            298695   \n",
       "AL          36.23             47.4               52.6           1049629   \n",
       "AR          32.77             48.6               51.4            589879   \n",
       "AZ          35.04             49.5               50.5           4499542   \n",
       "CA          36.18             49.5               50.5          24822460   \n",
       "\n",
       "Race   Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "State                                                             \n",
       "AK                    9.2          11.1                    2.77   \n",
       "AL                    6.8           5.0                    2.43   \n",
       "AR                    5.4          10.5                    2.53   \n",
       "AZ                    5.9          15.2                    2.77   \n",
       "CA                    3.7          30.0                    3.10   \n",
       "\n",
       "Race   American Indian and Alaska Native  Asian  Black or African-American  \\\n",
       "State                                                                        \n",
       "AK                                  12.2   12.3                        7.7   \n",
       "AL                                   0.8    2.7                       49.6   \n",
       "AR                                   1.6    3.7                       25.4   \n",
       "AZ                                   2.9    5.1                        6.6   \n",
       "CA                                   1.6   18.3                        8.2   \n",
       "\n",
       "Race   Hispanic or Latino  White  \n",
       "State                             \n",
       "AK                    9.1   71.2  \n",
       "AL                    3.7   47.5  \n",
       "AR                   13.2   65.2  \n",
       "AZ                   33.5   79.8  \n",
       "CA                   39.7   60.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert population columns except total to % of the state\n",
    "states_cols = list(states_pivot.columns)\n",
    "states_cols.remove('Median Age')\n",
    "states_cols.remove('Total Population')\n",
    "states_cols.remove('Average Household Size')\n",
    "for col in states_cols:\n",
    "    states_pivot[col] = round(states_pivot[col]/states_pivot['Total Population'],3)*100\n",
    "states_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert total population column to % of country total\n",
    "states_pivot['Total Population'] = round(states_pivot['Total Population']/sum(states_pivot['Total Population']),3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>32.20</td>\n",
       "      <td>51.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>36.23</td>\n",
       "      <td>47.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>49.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>47.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>32.77</td>\n",
       "      <td>48.6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>35.04</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>36.18</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>39.7</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race   Median Age  Male Population  Female Population  Total Population  \\\n",
       "State                                                                     \n",
       "AK          32.20             51.2               48.8               0.3   \n",
       "AL          36.23             47.4               52.6               0.9   \n",
       "AR          32.77             48.6               51.4               0.5   \n",
       "AZ          35.04             49.5               50.5               3.9   \n",
       "CA          36.18             49.5               50.5              21.5   \n",
       "\n",
       "Race   Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "State                                                             \n",
       "AK                    9.2          11.1                    2.77   \n",
       "AL                    6.8           5.0                    2.43   \n",
       "AR                    5.4          10.5                    2.53   \n",
       "AZ                    5.9          15.2                    2.77   \n",
       "CA                    3.7          30.0                    3.10   \n",
       "\n",
       "Race   American Indian and Alaska Native  Asian  Black or African-American  \\\n",
       "State                                                                        \n",
       "AK                                  12.2   12.3                        7.7   \n",
       "AL                                   0.8    2.7                       49.6   \n",
       "AR                                   1.6    3.7                       25.4   \n",
       "AZ                                   2.9    5.1                        6.6   \n",
       "CA                                   1.6   18.3                        8.2   \n",
       "\n",
       "Race   Hispanic or Latino  White  \n",
       "State                             \n",
       "AK                    9.1   71.2  \n",
       "AL                    3.7   47.5  \n",
       "AR                   13.2   65.2  \n",
       "AZ                   33.5   79.8  \n",
       "CA                   39.7   60.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "states_pivot.to_csv('data_second_cleaning/states.csv', index=True) #save for to use in step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Immigration Data\n",
    "Let's explore the immigration sample data since it will be much easier to work with than the SAS data. This will allow us to identify the cleaning steps necessary on the larger set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 1000 rows and 29 columns of data in the immigration sample file\n",
      "columns are Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
      "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
      "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
      "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
      "       'airline', 'admnum', 'fltno', 'visatype'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "imm_df = pd.read_csv(\"data_first_cleaning/immigration_sample.csv\")\n",
    "stats_on_df(imm_df,\"immigration sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(imm_df['count'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is no purpose for the count column as every row contains an identical value. This will not be maintained in our data model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  3.  2.  9.]\n"
     ]
    }
   ],
   "source": [
    "print(imm_df.i94mode.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Numeric coding will be changed from 1 to air, 2 to sea, and 3 to land respectively. Then the air data can be joined with the airports.csv data to provided additional information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Temperature Data\n",
    "Let's explore the temperature data and see what cleaning is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 8599212 rows and 7 columns of data in the temperatures all cities file\n",
      "columns are Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
      "       'Country', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "temp_df_full = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv') \n",
    "stats_on_df(temp_df_full, 'temperatures all cities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "With over 8 million rows, this data will be very difficult to work with in Pandas. For our purposes, we do not need such extensive historical data. We can quickly truncate the data into a more manageable size by only maintaining recent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df_full['Year'] = temp_df_full['dt'].astype(str).str[:4].astype(int)\n",
    "temp_df_full.head()\n",
    "temp_recent = temp_df_full[temp_df_full['Year']>1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 958230 rows and 8 columns of data in the recent temps file\n",
      "columns are Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
      "       'Country', 'Latitude', 'Longitude', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "stats_on_df(temp_recent, 'recent temps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now that our dataset is less than 1 million rows, we can use pandas much more efficiently. We would like to prep our data so that we can easy have the following fields via an SQL query When loading our data in the data pipeline:\n",
    "\n",
    "- Highest monthly avg Temp (of most recent year)\n",
    "- Lowest monthly avg Temp  (of most recent year)\n",
    "- Temperature delta vs. 10 years ago (compare most recent year vs. 10 years prior)\n",
    "- Temperature delta vs. 20 years ago (compare most recent year vs. 20 years prior)\n",
    "\n",
    "Let's clean the data here so that we will be able to easily obtain the necessary fields in a SQL query in a later step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8599207</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>11.464</td>\n",
       "      <td>0.236</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599208</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>15.043</td>\n",
       "      <td>0.261</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599209</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>18.775</td>\n",
       "      <td>0.193</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599210</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>18.025</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599211</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "8599207  2013-05-01              11.464                          0.236   \n",
       "8599208  2013-06-01              15.043                          0.261   \n",
       "8599209  2013-07-01              18.775                          0.193   \n",
       "8599210  2013-08-01              18.025                          0.298   \n",
       "8599211  2013-09-01                 NaN                            NaN   \n",
       "\n",
       "           City      Country Latitude Longitude  Year  \n",
       "8599207  Zwolle  Netherlands   52.24N     5.26E  2013  \n",
       "8599208  Zwolle  Netherlands   52.24N     5.26E  2013  \n",
       "8599209  Zwolle  Netherlands   52.24N     5.26E  2013  \n",
       "8599210  Zwolle  Netherlands   52.24N     5.26E  2013  \n",
       "8599211  Zwolle  Netherlands   52.24N     5.26E  2013  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_recent.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 115830 rows and 8 columns of data in the recent temps file\n",
      "columns are Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
      "       'Country', 'Latitude', 'Longitude', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "years = [1993, 2003, 2013]\n",
    "temp_recent = temp_recent[temp_recent.Year.isin(years)]\n",
    "stats_on_df(temp_recent, 'recent temps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1982569</th>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>-2.738</td>\n",
       "      <td>0.173</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>82.91W</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982570</th>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>-5.685</td>\n",
       "      <td>0.292</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>82.91W</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982571</th>\n",
       "      <td>1993-03-01</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.378</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>82.91W</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982572</th>\n",
       "      <td>1993-04-01</td>\n",
       "      <td>7.350</td>\n",
       "      <td>0.222</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>82.91W</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982573</th>\n",
       "      <td>1993-05-01</td>\n",
       "      <td>14.436</td>\n",
       "      <td>0.302</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>82.91W</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "1982569  1993-01-01              -2.738                          0.173   \n",
       "1982570  1993-02-01              -5.685                          0.292   \n",
       "1982571  1993-03-01              -0.172                          0.378   \n",
       "1982572  1993-04-01               7.350                          0.222   \n",
       "1982573  1993-05-01              14.436                          0.302   \n",
       "\n",
       "            City        Country Latitude Longitude  Year  \n",
       "1982569  Detroit  United States   42.59N    82.91W  1993  \n",
       "1982570  Detroit  United States   42.59N    82.91W  1993  \n",
       "1982571  Detroit  United States   42.59N    82.91W  1993  \n",
       "1982572  Detroit  United States   42.59N    82.91W  1993  \n",
       "1982573  Detroit  United States   42.59N    82.91W  1993  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_recent[temp_recent['City']==\"Detroit\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here we can see that the temperature data has city and country, however our immigration data only gives us the intended state and not city for destination. Therefore we'll need to reference our cities dataset to get state for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 2891 rows and 12 columns of data in the city state reference file\n",
      "columns are Index(['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
      "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
      "       'Average Household Size', 'State Code', 'Race', 'Race Population'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "citystate_df = pd.read_csv('data_first_cleaning/cities.csv')\n",
    "stats_on_df(citystate_df, 'city state reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City     State\n",
       "144  Detroit  Michigan"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citystate_df = citystate_df[['City','State','Total Population']]\n",
    "citystate_df = citystate_df.groupby(['City','State']).aggregate('max') #remove duplicates\n",
    "citystate_df = citystate_df.reset_index()\n",
    "citystate_df = citystate_df[['City','State']]\n",
    "citystate_df[citystate_df.City=='Detroit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_joined = temp_recent.set_index('City').join(citystate_df.set_index('City'))\n",
    "temp_joined = temp_joined.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 116919 rows and 9 columns of data in the cities file\n",
      "columns are Index(['City', 'dt', 'AverageTemperature', 'AverageTemperatureUncertainty',\n",
      "       'Country', 'Latitude', 'Longitude', 'Year', 'State'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "stats_on_df(temp_joined, 'cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City          dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
      "0  A Coruña  1993-01-01               9.833                          0.455   \n",
      "1  A Coruña  1993-02-01               9.737                          0.659   \n",
      "2  A Coruña  1993-03-01              11.353                          0.246   \n",
      "3  A Coruña  1993-04-01              11.104                          0.234   \n",
      "4  A Coruña  1993-05-01              13.724                          0.473   \n",
      "\n",
      "  Country Latitude Longitude  Year State  \n",
      "0   Spain   42.59N     8.73W  1993   NaN  \n",
      "1   Spain   42.59N     8.73W  1993   NaN  \n",
      "2   Spain   42.59N     8.73W  1993   NaN  \n",
      "3   Spain   42.59N     8.73W  1993   NaN  \n",
      "4   Spain   42.59N     8.73W  1993   NaN  \n"
     ]
    }
   ],
   "source": [
    "print(temp_joined.head())\n",
    "temp_joined.loc[temp_joined.Country != 'United States','State'] = np.NaN\n",
    "#df.loc[df.ID == 103, 'FirstName'] = \"Matt\"\n",
    "temp_joined['Month'] = temp_joined['dt'].astype(str).str[5:7].astype(int)\n",
    "\n",
    "del temp_joined['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(temp_joined[temp_joined.Country=='Mexico'].State.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Latitude Longitude  Year    Country       City  AverageTemperature  \\\n",
      "0    0.80N   103.66E  1993   Malaysia    Sekudai              26.447   \n",
      "1    0.80N   103.66E  1993  Singapore  Singapore              26.447   \n",
      "2    0.80N   103.66E  2003   Malaysia    Sekudai              26.406   \n",
      "\n",
      "   AverageTemperatureUncertainty State  Month  avg_yrly_temp  \\\n",
      "0                          0.186   NaN     12          26.93   \n",
      "1                          0.186   NaN     12          26.93   \n",
      "2                          0.258   NaN     12          27.31   \n",
      "\n",
      "   mnthly_high_temp  mnthly_low_temp  \n",
      "0             27.95            26.19  \n",
      "1             27.95            26.19  \n",
      "2             28.57            26.41  \n"
     ]
    }
   ],
   "source": [
    "temp_df = temp_joined.copy()\n",
    "#Create min max and average data\n",
    "groupby_cols = ['Latitude','Longitude','Year', 'Country']\n",
    "temp_df['avg_yrly_temp']=round(temp_df.groupby(groupby_cols)['AverageTemperature'].transform('mean'),2)\n",
    "temp_df['mnthly_high_temp']=round(temp_df.groupby(groupby_cols)['AverageTemperature'].transform('max'),2)\n",
    "temp_df['mnthly_low_temp']=round(temp_df.groupby(groupby_cols)['AverageTemperature'].transform('min'),2)\n",
    "temp_df = temp_df.groupby(groupby_cols).last()\n",
    "temp_df.reset_index(inplace=True)\n",
    "print(temp_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Malaysia' 'Singapore' 'Indonesia' 'Congo (Democratic Republic Of The)'\n",
      " 'Uganda' 'Kenya' 'Somalia' 'Brazil' 'Colombia' 'Ecuador' 'Gabon'\n",
      " 'Tanzania' 'Nigeria' 'Vietnam' 'Philippines' 'Guinea' 'Cameroon' 'Benin'\n",
      " 'Burkina Faso' 'Ethiopia' 'Mali' 'Venezuela' 'India' 'Costa Rica' 'Peru'\n",
      " 'Thailand' 'Cambodia' 'Guinea Bissau' 'Senegal' 'Djibouti' 'Nicaragua'\n",
      " 'Burma' 'Angola' 'Zambia' 'Gambia' 'Niger' 'Sudan' 'Yemen' 'Honduras'\n",
      " 'El Salvador' 'Malawi' 'Mozambique' 'Eritrea' 'Guatemala' 'Mexico'\n",
      " 'Madagascar' 'Saudi Arabia' 'Oman' 'Australia' 'Bolivia' 'Laos'\n",
      " 'Mauritania' 'Puerto Rico' 'Dominican Republic' 'Haiti' 'Jamaica'\n",
      " 'Zimbabwe' 'Chile' 'Equatorial Guinea' 'Rwanda' 'China' 'Cuba' 'Mauritius'\n",
      " 'Reunion' 'Hong Kong' 'Taiwan' 'Egypt' 'Bangladesh' 'Namibia'\n",
      " 'South Africa' 'Qatar' 'United Arab Emirates' 'Pakistan' 'Bahamas'\n",
      " 'Botswana' 'Paraguay' 'Argentina' 'Libya' 'Bahrain' 'Iran' 'United States'\n",
      " 'Nepal' 'Swaziland' 'Spain' 'Morocco' 'Lesotho' 'Japan' 'Israel' 'Algeria'\n",
      " 'Afghanistan' 'Uruguay' 'Jordan' 'Lebanon' 'Syria' 'Iraq' 'Tunisia'\n",
      " 'Greece' 'Cyprus' 'Turkey' 'New Zealand' 'South Korea' 'Italy'\n",
      " 'Turkmenistan' 'Uzbekistan' 'Tajikistan' 'Portugal'\n",
      " 'Central African Republic' 'Congo' 'Burundi' 'Albania' 'Armenia' 'Georgia'\n",
      " 'Azerbaijan' 'Russia' 'Bosnia And Herzegovina' 'Montenegro' 'France'\n",
      " 'Macedonia' 'Serbia' 'Bulgaria' 'Kazakhstan' 'Canada' 'Croatia' 'Romania'\n",
      " 'Slovenia' 'Hungary' 'Ukraine' 'Switzerland' 'Austria' 'Germany'\n",
      " 'Mongolia' 'Slovakia' 'Moldova' 'Czech Republic' 'Ghana' \"Côte D'Ivoire\"\n",
      " 'Suriname' 'United Kingdom' 'Poland' 'Belgium' 'Netherlands' 'Belarus'\n",
      " 'Ireland' 'Denmark' 'Sweden' 'Lithuania' 'Latvia' 'Estonia' 'Norway'\n",
      " 'Finland' 'Iceland' 'Togo' 'Liberia' 'Guyana' 'Sri Lanka' 'Sierra Leone'\n",
      " 'Chad' 'Panama' 'Papua New Guinea']\n",
      "4302\n"
     ]
    }
   ],
   "source": [
    "print(temp_df.Country.unique())\n",
    "print(len(temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>avg_yrly_temp</th>\n",
       "      <th>mnthly_high_temp</th>\n",
       "      <th>mnthly_low_temp</th>\n",
       "      <th>temp_delta_10_yrs</th>\n",
       "      <th>temp_delta_20_yrs</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekudai</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.372</td>\n",
       "      <td>28.66</td>\n",
       "      <td>26.56</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>103.66E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.372</td>\n",
       "      <td>28.66</td>\n",
       "      <td>26.56</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>103.66E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singkawang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.684</td>\n",
       "      <td>29.23</td>\n",
       "      <td>27.13</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>108.48E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kuching</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.001</td>\n",
       "      <td>27.88</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>110.09E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bontang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.212</td>\n",
       "      <td>27.65</td>\n",
       "      <td>26.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>118.13E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gorontalo</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.652</td>\n",
       "      <td>26.95</td>\n",
       "      <td>25.98</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>122.95E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City    Country State  avg_yrly_temp  mnthly_high_temp  \\\n",
       "0     Sekudai   Malaysia   NaN         27.372             28.66   \n",
       "1   Singapore  Singapore   NaN         27.372             28.66   \n",
       "2  Singkawang  Indonesia   NaN         27.684             29.23   \n",
       "3     Kuching   Malaysia   NaN         27.001             27.88   \n",
       "4     Bontang  Indonesia   NaN         27.212             27.65   \n",
       "5   Gorontalo  Indonesia   NaN         26.652             26.95   \n",
       "\n",
       "   mnthly_low_temp  temp_delta_10_yrs  temp_delta_20_yrs Latitude Longitude  \n",
       "0            26.56               0.29               0.67    0.80N   103.66E  \n",
       "1            26.56               0.29               0.67    0.80N   103.66E  \n",
       "2            27.13               0.35               0.59    0.80N   108.48E  \n",
       "3            26.47               0.35               0.58    0.80N   110.09E  \n",
       "4            26.38               0.05               0.31    0.80N   118.13E  \n",
       "5            25.98              -0.20               0.19    0.80N   122.95E  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collapse on year\n",
    "temp_index = list(temp_df.columns)\n",
    "temp_index.remove('avg_yrly_temp')\n",
    "temp_index.remove('Year')\n",
    "temp_df = temp_df.fillna('dummy') #otherwise it drops countries due to State=NaN\n",
    "temp_pivot = pd.pivot_table(temp_df, values='avg_yrly_temp', index=temp_index, columns=['Year'], aggfunc=np.sum)\n",
    "temp_pivot = temp_pivot.reset_index()\n",
    "temp_pivot.columns = temp_pivot.columns.astype(str)\n",
    "temp_pivot['State'][temp_pivot.State=='dummy'] = np.nan #revert to nan\n",
    "\n",
    "#get delta values\n",
    "temp_pivot[['1993','2003','2013']] = temp_pivot[['1993','2003','2013']].fillna(method='ffill')\n",
    "temp_pivot = temp_pivot.iloc[2::3, :] #only keep 2013 rows\n",
    "temp_pivot['temp_delta_10_yrs'] = temp_pivot['2013']-temp_pivot['2003']\n",
    "temp_pivot['temp_delta_20_yrs'] = temp_pivot['2013']-temp_pivot['1993']\n",
    "temp_pivot.reset_index()\n",
    "\n",
    "#limit to relevant columns\n",
    "temp_columns = ['City', 'Country', 'State','avg_yrly_temp', 'mnthly_high_temp', 'mnthly_low_temp', 'temp_delta_10_yrs', 'temp_delta_20_yrs', 'Latitude','Longitude']\n",
    "temp_pivot = temp_pivot.rename(columns={'AverageTemperature':'avg_yrly_temp'})\n",
    "temp_pivot = temp_pivot.rename_axis(None, axis = 1)\n",
    "temp_pivot = temp_pivot.reset_index()\n",
    "temp_pivot = temp_pivot[temp_columns]\n",
    "\n",
    "temp_pivot.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_pivot.to_csv('data_second_cleaning/temperature.csv', index=False) #save for to use in step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This new temperature dataset is less than 1MB whereas we started with a dataset >500MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
