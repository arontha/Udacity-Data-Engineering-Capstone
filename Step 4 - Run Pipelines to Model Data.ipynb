{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sql_queries.create_tables import create_table_queries\n",
    "from sql_queries.insert_queries import insert_table_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = pd.read_csv(\"data_second_cleaning/airports.csv\")\n",
    "states_df = pd.read_csv(\"data_second_cleaning/states.csv\")\n",
    "temp_df = pd.read_csv(\"data_second_cleaning/temperature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Takes 10-15 minutes to load\n",
    "imm_df_raw =  pd.read_sas(\"../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat\", format='sas7bdat', index=None, encoding=None, chunksize=None, iterator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Transform data into load-ready dataframes and insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform destination_table\n",
    "states_df['dest_id'] = states_df['State']\n",
    "dest_cols = ['dest_id','State','Median Age','Total Population','White','Black or African-American','Asian','Hispanic or Latino','American Indian and Alaska Native','Foreign-born']\n",
    "destination_df = states_df[dest_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform geography_table (join airport_df and temp_df)\n",
    "#airport_df transform to join into geography_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Basis for joining temperature and airport data\n",
    "Problems:\n",
    "- Cannot join on city because there are multiple cities with the same name\n",
    "- Cannot easily take a city/country combination because countries are not in the same format\n",
    "- Cannot take the coordinates because the airport coordinates or for the airport vs. the temp which is the city center  \n",
    "\n",
    "Solution:\n",
    "- Only use cities with large airports to avoid repeated names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     airport_identifier   airport_size             airport_name  elevation_ft  \\\n",
      "1205               EGGW  large_airport     London Luton Airport         526.0   \n",
      "1219               EGKK  large_airport   London Gatwick Airport         202.0   \n",
      "1224               EGLL  large_airport  London Heathrow Airport          83.0   \n",
      "1261               EGSS  large_airport  London Stansted Airport         348.0   \n",
      "\n",
      "     continent country iso_region municipality gps_code iata_code local_code  \\\n",
      "1205        EU      GB     GB-ENG       London     EGGW       LTN        NaN   \n",
      "1219        EU      GB     GB-ENG       London     EGKK       LGW        NaN   \n",
      "1224        EU      GB     GB-ENG       London     EGLL       LHR        NaN   \n",
      "1261        EU      GB     GB-ENG       London     EGSS       STN        NaN   \n",
      "\n",
      "                                   coordinates  \n",
      "1205  -0.36833301186561584, 51.874698638916016  \n",
      "1219                      -0.190278, 51.148102  \n",
      "1224                        -0.461941, 51.4706  \n",
      "1261             0.234999999404, 51.8849983215  \n"
     ]
    }
   ],
   "source": [
    "large_airports = airport_df[airport_df.airport_size=='large_airport']\n",
    "double_airports = large_airports[large_airports.duplicated(subset=['municipality'],keep=False)]\n",
    "print(double_airports[double_airports.municipality=='London'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The large airports dataset does have rows with the same city in multiple rows, but that is because the city has multiple airports and not because they are for different cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#join airport_df and temp_df into geography_df\n",
    "geography_df = large_airports.copy()\n",
    "geography_df = geography_df.rename(columns={'municipality':'City'})\n",
    "\n",
    "geography_df = geography_df.set_index('City').join(temp_df.set_index('City'), how = 'left', lsuffix ='_airports', rsuffix='_temp')\n",
    "geography_df = geography_df.reset_index()\n",
    "\n",
    "#clean geography_df into insert_ready format\n",
    "geography_cols = ['airport_id', 'state', 'country', 'city', 'airport_name', 'elevation', 'continent', 'avg_yrly_temp', \\\n",
    "                  'mnthly_high_temp', 'mnthly_low_temp', 'temp_delta_10_yrs', 'temp_delta_20_yrs']\n",
    "geography_df = geography_df.rename(columns={'State':'state', 'City':'city', 'elevation_ft':'elevation', 'iata_code':'airport_id'})\n",
    "geography_df = geography_df[geography_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#date_table transform\n",
    "import datetime\n",
    "dates_df = pd.to_timedelta(imm_df_raw.arrdate.unique(), unit='D') + pd.Timestamp('1960-1-1')\n",
    "dates_df = pd.DataFrame(np.sort(dates_df))\n",
    "dates_df.columns = ['date_id']\n",
    "dates_df.date_id = pd.to_datetime(dates_df.date_id)\n",
    "dates_df['day'] = pd.DatetimeIndex(dates_df.date_id).day\n",
    "dates_df['week'] = pd.DatetimeIndex(dates_df.date_id).week\n",
    "dates_df['month'] = pd.DatetimeIndex(dates_df.date_id).month\n",
    "dates_df['year'] = pd.DatetimeIndex(dates_df.date_id).year\n",
    "dates_df['date_id'] = dates_df['date_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#uncomment this cell to work with a subset of the immigration data only\n",
    "#imm_df_copy = imm_df_raw.copy() #to avoid needing to read the sas data directly as that is very slow\n",
    "#imm_mini_df = imm_df_copy.head(250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_imm(df):\n",
    "    df = df.drop(['i94yr', 'i94mon', 'insnum', 'admnum', 'fltno', 'dtaddto', 'count', 'delete_days', \n",
    "       'delete_mexl', 'delete_dup', 'delete_visa', 'delete_recdup', 'validres', 'i94cit', 'depdate', 'dtadfile'], axis=1)\n",
    "    df = df.rename(columns={'cicid':'imm_id', 'i94res':'country_of_origin', 'visatype':'visatype', 'dtaddto':'i94_date',\n",
    "                            'biryear':'birth_year', 'i94bir':'age', 'i94port':'airport_id', 'gender':'gender', 'i94mode':'mode_transport', \n",
    "                            'visapost':'dos_issuing_office', 'entdepa':'arrival_flag', 'entdepu':'update_flag', 'entdepd':'departure_flag', \n",
    "                            'entdepm':'matching_flag', 'airline':'airline', 'i94visa':'visa_reason', 'occup':'occupation',\n",
    "                            'arrdate':'date_id', 'i94addr': 'dest_id'})\n",
    "\n",
    "    df.age = df.age.fillna(0)\n",
    "    df.country_of_origin = df.country_of_origin.fillna(0)\n",
    "    df.imm_id = df.imm_id.fillna(0)\n",
    "    df.birth_year = df.birth_year.fillna(1900)\n",
    "    \n",
    "    astype_dict = {'imm_id': int, 'country_of_origin': int, 'age': int, 'birth_year': int, \n",
    "                   'airport_id': str, 'mode_transport': str,'dest_id': str,'visa_reason': str,'dos_issuing_office': str,'occupation': str,\n",
    "                   'arrival_flag': str,'departure_flag': str, 'update_flag': str, 'matflag': str, 'gender': str,'airline': str,'visatype': str,\n",
    "               } \n",
    "    df = df.astype(astype_dict) \n",
    "       \n",
    "    country_df = df[['country_of_origin', 'birth_year']]\n",
    "    country_matrix = pd.read_csv('Misc/i94res matrix.csv', delimiter='\\t')\n",
    "    country_matrix.country_of_origin = country_matrix.country_of_origin.astype(int)\n",
    "    country_df = country_df.join(country_matrix, on ='country_of_origin', how ='left', lsuffix='delete')\n",
    "    df.country_of_origin = country_df.Country\n",
    "    \n",
    "    df.loc[df.mode_transport=='1.0', 'mode_transport'] = 'Air'\n",
    "    df.loc[df.mode_transport=='2.0', 'mode_transport'] = 'Sea'\n",
    "    df.loc[df.mode_transport=='3.0', 'mode_transport'] = 'Land'\n",
    "    \n",
    "    df.loc[df.visa_reason=='1.0', 'visa_reason'] = 'Business'\n",
    "    df.loc[df.visa_reason=='2.0', 'visa_reason'] = 'Pleasure'\n",
    "    df.loc[df.visa_reason=='3.0', 'visa_reason'] = 'Student'\n",
    "\n",
    "    df.date_id = pd.to_timedelta(df.date_id, unit='D') + pd.Timestamp('1960-1-1')\n",
    "    df.date_id = df.date_id.dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    b_first = ['dest_id', 'airport_id', 'dos_issuing_office', 'arrival_flag', 'departure_flag', 'update_flag', 'matflag', 'gender', 'airline', 'visatype']\n",
    "    for col in b_first:\n",
    "        df[col] = df[col].apply(lambda x : x[1:] if x.startswith(\"b\") else x)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#immigration_table\n",
    "#imm_df = clean_imm(imm_mini_df)\n",
    "#60 minutes\n",
    "imm_df = clean_imm(imm_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   imm_id           country_of_origin airport_id     date_id mode_transport  \\\n",
      "0       4  MAYOTTE (AFRICA - FRENCH)'      'XXX'  2016-06-07            nan   \n",
      "\n",
      "  dest_id  age visa_reason dos_issuing_office occupation arrival_flag  \\\n",
      "0     nan   59    Pleasure                nan        nan          'Z'   \n",
      "\n",
      "  departure_flag update_flag matflag  birth_year gender airline visatype  \n",
      "0            nan         'U'     nan        1957    nan     nan     'WT'  \n"
     ]
    }
   ],
   "source": [
    "print(imm_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As a reminder from step 1, the raw immigration dataset has the following fields:\n",
    "- cicid: unique identifier\n",
    "- i94yr: 4 digit year\n",
    "- i94mon: numeric month\n",
    "- i94cit: origin code for processing (3 numbers)\n",
    "- i94res: origin code for processing (3 numbers)\n",
    "- i94port: airport code of arrival to US (3 letters)\n",
    "- arrdate: Arrival date to US\n",
    "- i94mode: Mode of transportation on arrival (air, sea, land as 1, 2, and 3 respectively)\n",
    "- i94addr: 2 letter state code of destination\n",
    "- depdate: Departure date from US\n",
    "- i94bir: Age of individual in years\n",
    "- i94visa: visa reason codes (1, 2, 3 for business, pleasure or student respectively)\n",
    "- count: contains value of 1 for summarizing\n",
    "- dtadfile: date field yyyymmdd format\n",
    "- visapost: dept of state branch issuing visa\n",
    "- occup: occupation to perform in US\n",
    "- entdepa: arrival flag  (admitted or paroled)\n",
    "- entdepd: departure flag (departed, lost or deceased)\n",
    "- entdepu: update flag (apprehended, overstayed, adjusted to permanent residence)\n",
    "- matflag: flag if arrival/departure records matching\n",
    "- biryear: 4 digit birth year\n",
    "- dtaddto: date allowed to stay in US until\n",
    "- gender: gender code (1 letter abbreviation)\n",
    "- insnum: INS number\n",
    "- airline: airline flown to arrive in US\n",
    "- admnum: admission number\n",
    "- fltno: flight number of airline flown to arrive in US\n",
    "- visatype: admission class of visa for non-immigrant family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#10 minutes\n",
    "immigration_cols = list(imm_df.columns)\n",
    "immigration_cols.remove('dest_id')\n",
    "immigration_cols.remove('date_id')\n",
    "immigration_cols.remove('airport_id')\n",
    "immigration_df = imm_df[immigration_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#facts_table\n",
    "facts_cols = ['imm_id', 'date_id', 'dest_id', 'country_of_origin', 'airport_id']\n",
    "facts_df = imm_df[facts_cols]\n",
    "facts_cols[3] = 'origin_id'\n",
    "facts_df.columns = facts_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_for_load(df):\n",
    "    df1 = df.replace(\"'\", \"\", regex=True)\n",
    "    df2 = df1.replace('\"', '', regex=True)   \n",
    "    df3 = df2.replace(\"nan\", \"NULL\")\n",
    "    df4 = df3.replace(np.nan, 'NULL')\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#55 minutes\n",
    "raw_load_dfs = [facts_df, destination_df, geography_df, dates_df, immigration_df]\n",
    "load_dfs = []\n",
    "for df in raw_load_dfs:\n",
    "    df2 = format_for_load(df)\n",
    "    load_dfs.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_nulls = load_dfs[2].replace('NULL', -100)\n",
    "load_dfs[2] = df_nulls.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create Redshift DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries.quality_checks import quality_check_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Misc/dwh.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('Misc/dwh.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create tables\n",
    "for create_query in create_table_queries:\n",
    "    cur.execute(create_query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, '2016-06-07', 'NULL', 'MAYOTTE (AFRICA - FRENCH)', 'XXX')\n",
      "(5, '2016-06-07', 'NULL', 'MAYOTTE (AFRICA - FRENCH)', 'XXX')\n",
      "('AK', 'AK', 32.2, 0.3, 71.2, 7.7, 12.3, 9.1, 12.2, 11.1)\n",
      "('AL', 'AL', 36.23, 0.8999999999999999, 47.5, 49.6, 2.7, 3.7, 0.8, 5.0)\n",
      "('AAL', -100, 'DK', 'Aalborg', 'Aalborg Airport', 10.0, 'EU', -100.0, -100.0, -100.0, -100.0, -100.0)\n",
      "('ABZ', -100, 'GB', 'Aberdeen', 'Aberdeen Dyce Airport', 215.0, 'EU', 14.628, 14.77, 2.79, -1.4800000000000004, 0.009999999999999787)\n",
      "('2016-06-01', 1, 22, 6, 2016)\n",
      "('2016-06-02', 2, 22, 6, 2016)\n",
      "(4, 'MAYOTTE (AFRICA - FRENCH)', 'NULL', 59, 'Pleasure', 'NULL', 'NULL', 'Z', 'NULL', 'U', 'NULL', 1957, 'NULL', 'NULL', 'WT')\n",
      "(5, 'MAYOTTE (AFRICA - FRENCH)', 'NULL', 50, 'Pleasure', 'NULL', 'NULL', 'Z', 'NULL', 'U', 'NULL', 1966, 'NULL', 'NULL', 'WT')\n"
     ]
    }
   ],
   "source": [
    "#run insert table queries\n",
    "#30 minutes\n",
    "for df, insert_query in zip(load_dfs, insert_table_queries):\n",
    "    query = insert_query\n",
    "    for i,row in df.iterrows():\n",
    "        if i <2: print(str(tuple(row.values)))\n",
    "        query = query + str(tuple(row.values)) + ', ' \n",
    "        if (i+1)%10000==0:\n",
    "            cur.execute(query[:-2])\n",
    "            conn.commit()\n",
    "            query = insert_query\n",
    "    if query[-7:] != 'values ':\n",
    "        cur.execute(query[:-2])\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3574989 rows returned by SELECT COUNT(*) FROM facts_table.\n",
      "48 rows returned by SELECT COUNT(*) FROM destination_table.\n",
      "610 rows returned by SELECT COUNT(*) FROM geography_table.\n",
      "30 rows returned by SELECT COUNT(*) FROM date_table.\n"
     ]
    }
   ],
   "source": [
    "for quality_query in quality_check_queries[:-1]:\n",
    "    cur.execute(quality_query)\n",
    "    try:\n",
    "        print(f'{cur.fetchone()[0]} rows returned by {quality_query}.')\n",
    "    except:\n",
    "        print(f'{quality_query} returned an empty table!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dest_report = '''SELECT COUNT(imm_id) as Num_People, dest_id as State\n",
    "FROM facts_table\n",
    "GROUP BY State\n",
    "ORDER BY Num_People DESC\n",
    "LIMIT 10;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular destination of immigrants:\n",
      "\n",
      "SELECT COUNT(imm_id) as Num_People, dest_id as State\n",
      "FROM facts_table\n",
      "GROUP BY State\n",
      "ORDER BY Num_People DESC\n",
      "LIMIT 10;\n",
      "\n",
      "returns the following:\n",
      "[603181, 'CA']\n",
      "[589603, 'NY']\n",
      "[584520, 'FL']\n",
      "[186031, 'NULL']\n",
      "[184452, 'HI']\n",
      "[144576, 'TX']\n",
      "[121027, 'IL']\n",
      "[113264, 'NV']\n",
      "[105693, 'GU']\n",
      "[105193, 'MA']\n"
     ]
    }
   ],
   "source": [
    "cur.execute(imm_dest_report)\n",
    "results = cur.fetchall()\n",
    "print('Most popular destination of immigrants:')\n",
    "print(f'\\n{imm_dest_report}\\n\\nreturns the following:')\n",
    "for x in results:\n",
    "    print([y for y in x])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_latino_report = '''SELECT COUNT(FT.imm_id) as Num_People, FT.dest_id as State, DT.latino\n",
    "FROM facts_table FT JOIN destination_table DT ON FT.dest_id = DT.dest_id\n",
    "WHERE DT.latino>20\n",
    "GROUP BY FT.dest_id, DT.latino\n",
    "ORDER BY Num_People DESC\n",
    "LIMIT 10;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular destination of immigrants to states with >20% latino population:\n",
      "\n",
      "SELECT COUNT(FT.imm_id) as Num_People, FT.dest_id as State, DT.latino\n",
      "FROM facts_table FT JOIN destination_table DT ON FT.dest_id = DT.dest_id\n",
      "WHERE DT.latino>20\n",
      "GROUP BY FT.dest_id, DT.latino\n",
      "ORDER BY Num_People DESC\n",
      "LIMIT 10;\n",
      "\n",
      "returns the following:\n",
      "[603181, 'CA', 39.7]\n",
      "[589603, 'NY', 27.8]\n",
      "[584520, 'FL', 28.9]\n",
      "[144576, 'TX', 44.1]\n",
      "[121027, 'IL', 26.6]\n",
      "[113264, 'NV', 30.8]\n",
      "[105193, 'MA', 21.5]\n",
      "[105030, 'NJ', 42.0]\n",
      "[28878, 'CO', 24.0]\n",
      "[21620, 'AZ', 33.5]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(imm_latino_report)\n",
    "results = cur.fetchall()\n",
    "print('Most popular destination of immigrants to states with >20% latino population:')\n",
    "print(f'\\n{imm_latino_report}\\n\\nreturns the following:')\n",
    "for x in results:\n",
    "    print([y for y in x])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### See Data_Dictionary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
